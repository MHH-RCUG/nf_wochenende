// nf_wochenende nextflow configuration file
//configure these values to your own cluster queues and type, or just use local for the current machine

executor {
  //name = 'lsf'
  name = 'local'
  perJobMemLimit = true
  queue = 'bioinformatics'
  memory = '30 GB'
  cpus = 8

}

params {

  // Runtime parameters
  // Commonly changed parameters can be set here instead of using the start_nf.sh bash script

  //ref = "/mnt/beegfs/scratch/bioinformatics/colin/dev/nf_wochenende/current/nf_wochenende/test/data/ref.fa"
  //ref = "/mnt/beegfs/scratch/bioinformatics/colin/seqres/metagenref/wochenende/2021_12_human_bact_arch_fungi_vir.fa"
  ref = "/home/colin/projects/nf_wochenende/test/data/ref.fa"
  //ref = "/home/colin/projects/refseq/2021_12_human_bact_arch_fungi_vir.fa"
  
  aligner = "bwamem"    // Aligner software to use (bwamem, minimap2short, minimap2long, ngmlr)
  mismatches = "5"          // Exclude reads with x of more mismatches. Suggest 3-5 for short reads, 10000+ for long reads (integer)
  readType = "PE"             // SE single ended or PE paired end (SE, PE)
  mapping_quality = "mq30"    // Mapping quality filter. (mq20, mq30)
  longread = false             // Are reads from ONT or Pacbio. Recommend minimap2long aligner. (true, false)
  no_dup_removal = false      // Do not remove duplicate reads
  remove_secondary = true     // Remove secondary read alignments. Leave as true to avoid cryptic error. (true, false)
  remove_supplementary = true     // Remove supplementary read alignments. Leave as true to avoid cryptic error. (true, false)
  nextera = false             // Use illumina nextera adapter trimming (true, false)
  abra = false                // Use abra2 read realignment (true, false)
  no_prinseq = true           // Filter reads using prinseq (only for short reads) (true, false)
  no_fastqc = true            // Do not run fastqc (true, false)
  fastp = false               // Use fastp trimming tool (short reads) (true, false)
  trim_galore = false         // Use trim_galore trimmer (best for nextera short reads) (true, false)
  
  // Select which optional stages should be run. All require wochenende stage.
  stage_reporting = true      // run this stage, [true, false].
  stage_haybaler = true       // run this stage, [true, false]. Requires reporting
  stage_plots = true          // run this stage, [true, false]. 
  stage_growth_rate = true    // run this stage, [true, false].
  stage_raspir = true         // run this stage, [true, false].
  stage_multiqc = true        // run this stage, [true, false].  
  stage_heattrees = false      // run this stage, [true, false]. Requires configured R server and haybaler stage results.
  stage_heatmaps = false       // run this stage, [true, false]. Requires configured R server and haybaler stage results.
  

 // Haybaler aggregation tool lower thresholds. Taxa with read counts etc below these are excluded: 
  // 1. Minimum readcounts per sample. Chromosomes with less than x reads in every sample are filtered out! Default = 10
  // 2. Minimum RPMM per sample. Chromosomes with less than x RPMM in every sample are filtered out. Default = 300
  // Recommended settings for most users
  haybaler_readcount_limit = 10
  haybaler_rpmm_limit = 300
  // haybaler for tiny developer fastq datasets
  //haybaler_readcount_limit = 1
  //haybaler_rpmm_limit = 10

  // Installation parameters
  // set these to your local nf_Wochenende or haybaler paths (which you cloned from github)
  WOCHENENDE_DIR="/home/colin/projects/nf_wochenende"
  HAYBALER_DIR="/home/colin/projects/haybaler"

  // set these paths to the conda or haybaler conda environments you installed
  conda_wochenende = "/home/colin/miniconda3/envs/wochenende/"
  conda_haybaler   = "/home/colin/miniconda3/envs/haybaler/"

  // path to the Rscript binary on your R server
  rscript_bin = "/usr/bin/Rscript"

}



process {


  errorStrategy = 'retry'
  maxRetries    = 3

  withName: 'wochenende' {
    memory = { 30.GB * task.attempt }
    cpus = 8
    queue = ''
    clusterOptions = ""
    errorStrategy = 'terminate'
    // Use conda env defined in nextflow.config file
    conda = params.conda_wochenende
  }
  withName: 'reporting' {
    memory = { 8.GB * task.attempt }
    cpus = 1
    queue = ''
    clusterOptions = ""
    errorStrategy  = 'ignore'
    conda = params.conda_wochenende
  }
  withName: 'haybaler' {
    memory = { 8.GB * task.attempt }
    cpus = 1
    queue = ''
    clusterOptions = "- your_r_server"
    errorStrategy = 'retry'
    conda = params.conda_haybaler
  }
  withName: 'plots' {
    memory = { 8.GB * task.attempt }
    cpus = 1
    queue = ''
    clusterOptions = ""
    errorStrategy  = 'retry'
    // Use conda env defined in nextflow.config file
    conda = params.conda_wochenende
  }
  withName: 'growth_rate' {
    memory = { 16.GB * task.attempt }
    cpus = 1
    queue = ''
    clusterOptions = ""
    errorStrategy  = 'retry'
    // Use conda env defined in nextflow.config file
    conda = params.conda_wochenende
  }
  withName: 'raspir_fileprep' {
    memory = { 8.GB * task.attempt }
    cpus = 8
    queue = ''
    clusterOptions = ""
    errorStrategy = 'retry'
    // Use conda env defined in nextflow.config file
    conda = params.conda_haybaler
  }
  withName: 'raspir' {
    memory = { 8.GB * task.attempt }
    cpus = 1
    queue = ''
    clusterOptions = ""
    errorStrategy  = 'retry'
    // Use conda env defined in nextflow.config file
    conda = params.conda_haybaler
  }
  withName: 'convert_bam_cram' {
    memory = { 24.GB * task.attempt }
    cpus = 8
    queue = ''
    clusterOptions = ""
    errorStrategy = 'retry'
    // Use conda env defined in nextflow.config file
    conda = params.conda_haybaler
  }
  withName: 'multiqc' {
    memory = { 4.GB * task.attempt }
    cpus = 1
    queue = ''
    clusterOptions = ""
    errorStrategy = 'ignore'
    // Use conda env defined in nextflow.config file
    conda = params.conda_haybaler
  }

  // configure this to an R server
  withName: 'run_r' {
    memory = '30 GB'
    cpus = 1
    queue = ''
    clusterOptions = "- your_r_server"
  }
  

}

